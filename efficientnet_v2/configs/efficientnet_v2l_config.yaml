
# Weights & Biases 설정
wandb:
  project: "efficientnet-finetune-car" # W&B에 표시될 프로젝트 이름
  entity: null                         # ⭐️ 사용자의 W&B 아이디 또는 팀 이름 (필수 수정)
  name: "effnet-v2l-run-${now:%Y-%m-%d_%H-%M-%S}" # 실행 이름 (시간으로 자동 생성)
  log_model: False

# 데이터 설정
data:
  module_name: "ImageFolderDataModule" # 우리가 만들 데이터 모듈 이름
  train_dir: "../dataset/train"                  # 학습 데이터 경로
  val_split: 0.2                      # 검증 데이터 분할 비율
  batch_size: 32
  num_workers: 8

# 모델 설정
model:
  module_name: "EfficientNetFineTuner"
  model_variant: "V2L"
  num_classes: 396
  phase1_epochs: 30
  phase2_epochs: 200
  # ⭐️ [수정 3] 8개 GPU에 맞춰 학습률 8배 증가
  learning_rate_phase1: 0.008 # 0.001 * 8
  learning_rate_phase2: 0.00008 # 0.00001 * 8

# Trainer 및 콜백 설정
trainer:
  accelerator: "gpu"
  devices: 8
  strategy: 'ddp'  # 또는 'ddp_spawn', 'ddp_fork' 
  sync_batchnorm: True
  # 총 에폭은 두 단계의 합입니다.
  max_epochs: 120 # phase1_epochs + phase2_epochs
  # precision: "16-mixed"

# 콜백(Callback) 설정
callbacks:
  early_stopping:
    monitor: "val_acc" # 검증 정확도를 기준으로
    mode: "max"
    patience: 10
    verbose: true
  
  model_checkpoint:
    dirpath: "./outputs/checkpoints/efficientnet_v2l/" # 체크포인트 저장 경로 명시
    monitor: "val_acc"
    mode: "max"
    filename: "efficientnet-v2l-{epoch:02d}-{val_acc:.4f}"
    save_top_k: 1
    auto_insert_metric_name: false