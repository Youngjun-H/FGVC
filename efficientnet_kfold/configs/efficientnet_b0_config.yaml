# ⭐️ 추가: K-Fold 교차 검증 설정
k_fold:
  n_splits: 5 # 5개의 폴드로 나누어 5개의 모델을 학습

# Weights & Biases 설정 (그룹으로 묶어 관리)
wandb:
  project: "efficientnet-kfold-ensemble"
  entity: "${WANDB_ENTITY}" 
  # ⭐️ group을 사용하여 K-Fold 실행을 하나의 실험 그룹으로 묶습니다.
  group: "kfold-run-${now:%Y-%m-%d_%H-%M-%S}"
  # 개별 실행 이름은 train.py에서 동적으로 설정합니다.             # 'all' 또는 true: 체크포인트를 W&B에 아티팩트로 저장

# # 데이터 설정
# data:
#   module_name: "ImageFolderDataModule" # 우리가 만들 데이터 모듈 이름
#   train_dir: "../dataset/train"                  # 학습 데이터 경로
#   val_split: 0.2                      # 검증 데이터 분할 비율
#   batch_size: 256
#   num_workers: 8

# 데이터 설정
data:
  # ⭐️ 이제 전체 데이터를 사용하므로 train_dir -> data_dir로 변경
  data_dir: "../dataset/train"                  # 학습 데이터 경로
  batch_size: 32 # 1-GPU 기준, 전체 배치 사이즈를 32로 유지하려면 32/GPU개수로 설정
  num_workers: 16

# 모델 설정
# model:
#   module_name: "EfficientNetFineTuner"
#   model_variant: "B0"
#   num_classes: 396
#   phase1_epochs: 20
#   phase2_epochs: 100
#   # ⭐️ [수정 3] 8개 GPU에 맞춰 학습률 8배 증가
#   learning_rate_phase1: 0.008 # 0.001 * 8
#   learning_rate_phase2: 0.00008 # 0.00001 * 8

# 모델 설정 (단순화)
model:
  module_name: "EfficientNetFineTuner"
  model_variant: "B0"
  num_classes: 396
  learning_rate: 0.001 # 단일 학습률만 사용

# Trainer 및 콜백 설정
trainer:
  accelerator: "gpu"
  devices: 8
  strategy: 'ddp'  # 또는 'ddp_spawn', 'ddp_fork' 
  sync_batchnorm: True
  # 총 에폭은 두 단계의 합입니다.
  max_epochs: 120 # phase1_epochs + phase2_epochs
  precision: "16-mixed"

# 콜백(Callback) 설정
callbacks:
  early_stopping:
    monitor: "val_acc" # 검증 정확도를 기준으로
    mode: "max"
    patience: 10
    verbose: true
  
  model_checkpoint:
    dirpath: "./outputs/checkpoints/efficientnet_b0_kfold/" # 체크포인트 저장 경로 명시
    monitor: "val_acc"
    mode: "max"
    filename: "efficientnet-b0-{epoch:02d}-{val_acc:.4f}"
    save_top_k: 1
    auto_insert_metric_name: false